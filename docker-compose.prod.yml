version: "3.9"

# Production build for local testing before GCloud deployment
# Usage: docker compose -f docker-compose.prod.yml up --build
#
# For actual GCloud deployment, use GitHub Actions:
#   .github/workflows/deploy-api.yml
#
# GCloud Stack:
#   API:     Cloud Run (asia-northeast3)
#   DB:      Cloud SQL PostgreSQL 16 + pgvector (Private IP)
#   Storage: Cloud Storage (GCS)
#   Secrets: Secret Manager
#   Images:  Artifact Registry

services:
  # Local PostgreSQL with pgvector (mirrors Cloud SQL PG16)
  db:
    image: pgvector/pgvector:pg16
    container_name: food-ai-db-prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
      POSTGRES_DB: food_ai_agent
    volumes:
      - pgdata_prod:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    # In production (Cloud Run), DB is Cloud SQL — no exposed port needed
    # ports:
    #   - "5432:5432"

  backend:
    build:
      context: ./food-ai-agent-api
      dockerfile: Dockerfile
      target: production   # Use multi-stage build production target
    container_name: food-ai-backend-prod
    image: food-ai-agent-api:prod
    environment:
      # When running locally against Cloud SQL, use Unix socket:
      # DATABASE_URL=postgresql+asyncpg://user:pass@/food_ai_agent?host=/cloudsql/PROJECT:REGION:INSTANCE
      DATABASE_URL: ${DATABASE_URL:?DATABASE_URL is required}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:?JWT_SECRET_KEY is required}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:?ANTHROPIC_API_KEY is required}
      OPENAI_API_KEY: ${OPENAI_API_KEY:?OPENAI_API_KEY is required}
      CORS_ORIGINS: ${CORS_ORIGINS:-["https://foodai.example.com"]}
      APP_ENV: production
      DEBUG: "false"
      CLAUDE_MODEL: ${CLAUDE_MODEL:-claude-sonnet-4-6}
      CLAUDE_MAX_TOKENS: ${CLAUDE_MAX_TOKENS:-4096}
      EMBEDDING_MODEL: ${EMBEDDING_MODEL:-text-embedding-3-small}
      EMBEDDING_DIMENSION: ${EMBEDDING_DIMENSION:-1536}
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
    command: >
      sh -c "
        alembic -c alembic/alembic.ini upgrade head &&
        uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 2
      "
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Frontend is deployed to Vercel — not included in production compose
  # For local prod build testing only:
  frontend:
    build:
      context: ./food-ai-agent-web
      dockerfile: Dockerfile
    container_name: food-ai-frontend-prod
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-https://food-ai-agent-api-xxxx-an.a.run.app/api/v1}
    ports:
      - "3000:3000"
    depends_on:
      - backend
    restart: unless-stopped
    profiles:
      - with-frontend  # Only start when explicitly requested

volumes:
  pgdata_prod:
